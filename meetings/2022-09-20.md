# NetworkX Developer Discussions: September 20th, 2022

Previous meeting notes available [here](https://github.com/networkx/archive/tree/main/meetings). Please feel free to add topics for discussion and news items below.

**In attendance:** Ross, Dan, Matt

## Welcome and news

- NumFOCUS summit 9/21 - 9/23

## Important dates/deadlines

- New meeting time: Tuesdays, 10AM Pacific time
- NX 3.0 release: late summer 2022
  
## Topics

- Outreachy round 2
  * New mentored project ideas?
    - Right now: nx-guides is the main project

- Needs decision: harmonic distance: https://github.com/networkx/networkx/pull/5251
  * Paper referenced in docstring: https://arxiv.org/abs/cond-mat/0008357
  * A lot of possibilities here (relate to harmonic centrality, average shortest path length?) with no clear-cut best approach

- Needs decision: rank maximal matching https://github.com/networkx/networkx/pull/5585
  * General consensus that this is a nice fit - move forward with code review

- This OpenRefactory PR seems spammy to me (Ross) - should we close? https://github.com/networkx/networkx/pull/5960
  * No real objections to closing

- A "long term" item addressed! (hopefully):

  > Another one: configure CI to stop running tests from a previous commit when a new commit is pushed up (I think scipy does this, so can copy their config)

  Indeed I copied the scipy/numpy GHA config to get the auto-cancel-on-new-push feature running. I did a little testing on my fork and it seems to work okay, though matrix-ed jobs might not respond immediately. Keep an eye out for potential improvements!
  
- pytest-randomly
  * Matt noticed that he's getting `pytest-randomly` failure emails *from his fork* - we should check the scheduled job and make sure it's set up only to run on the main fork

## Long-term tracking items

- We should try to automate the release process as much as possible so that we could remove a human from the release process. conda-forge has a very automated release system. Would a SPEC covering automated releases be reasonable?

- Post NX 3 release: A roadmap review.
  - better work with other packages. pygraphviz needs wheels -- getting there
  - GraphBLAS
  - We should have a "roadmap meeting" 
  - parallel backends? its different from backends, but maybe similar?
  
- Review public interface: For v3.0 should we be looking at the import structure?  Some subpackages are not imported to the main namespace. We have decided that based on history of how they were first committed. Is there a good way to decide which should require an extra referal: `network.community.modularity` instead of `networkx.modularity`?
  - First decision: what do we *want* the interface to be?
  - Module/pkg `__dir__` provides a nice way to modify discoverability of modules/packages **without** breaking existing code
  - NX-guide idea: model/visualize the package as a DAG (thanks Matt!)

- LaTeX interface
   - #5702 has two interfaces: TikZ and adigraph. The adigraph takes values for 3 node attributes like `G.nodes[2]["width"]=3`, while the TikZ version needs values to be strings like "[width=3]" for lots and lots of parameters allowed by TikZ.
   - Do we want two interfaces? what should the interface be?

- keywords arrows, arrowstyle, connectionstyle. Can we improve this interface? [#5694](https://github.com/networkx/networkx/pull/5694) and a link to the [current interface](https://github.com/networkx/networkx/blob/2c904d18dc79df3acd64495ef64c6ff4674992a0/networkx/drawing/nx_pylab.py#L537)
    - Need to indicate:
      o FancyArrowPatch or LineCollection
      o The arrowstyle (head or not or both, etc)
      o The connectionstyle (arc bendable etc)
    - Maybe changing the name of `arrows` to `fancyedges` would help
    - New logic could be:  If non-default value for either arrowstyle or connectionstyle then switch to FancyArrowPatch.
    - milestone this for v3.0

- Property-based testing
  * Check out `hypothesis` for setting up property-based testing
  * Developing good property-based tests:
    - Reference "naive" (but correct) implementation
    - Generate random graphs, evaluate them for the property you want
    - Pump these through the naive implementation and collect interesting cases for test suite

- Looking at the Roadmap - what do we want on there?
  * Some ideas:
    - GraphBLAS in the performance section
    - Temporal networks, hypergraphs, other new graph types?
    - Make testing more comprehensive -- mixed node types, hashable nodes, etc. (hypothesis?)
    - Benchmarking suites to at least run locally some timing.

- Temporal networks: how to think about these
  * seems to be a lot of interest from different communities, but no standard approach yet...
  * Having a use-case to drive the design of a data structure would be good
  
- Stop building/shipping pdf version of documentation?
  * This is being considered by both scipy and numpy and seems to have garnered mostly positive feedback
    - related scipy issue: https://github.com/scipy/scipy/issues/15635
  * revisit after 2.8 release
  * Keep up-to-date with feedback from other projects that are considering this

- nx-guides
  * We need a contributor guide :book: [name=Mridul]
  * Dependency management for tutorials - how to strike a balance between tools people use and maintainability

- New contributors
  * So many good students/contributions - how do we keep the ball rolling (even if we can only accept 1 or a subset of them for this round)
    - Add something to contributor guide about where to look for good issues (e.g. add missing docstring examples)
    - Link to [first issue tag](https://github.com/networkx/networkx/labels/Good%20First%20Issue) on github?
    
- Revisiting our pytest `slow` mark:
  * The `slow` tests are run w/ each push/PR in the coverage job; however, it's not necessarily true that the slow tests improve coverage!
  * Could save a lot of CI time by having a separate category (e.g. `pytest.mark.comprehensive`?) that is for tests that are slow but *don't* affect coverage. These could be run less frequently (scheduled job?) and potentially save several minutes for each push
    - General consensus: seems like a good idea
    - (Jarrod) maybe worth waiting until after the code removal sprint?

- Other CI-saving ideas
    - All tests should depend on the lint action, so all the other tests fail fast.

- [name=MridulS] I signed up on Tidelift to test it again, they have replied with a link to the [lifter agreement](https://support.tidelift.com/hc/en-us/articles/4406309657876-Lifter-agreement) and asked me if there are any issues with this. I will reach out again if there are no issues about this.
  * Hoops:
    * Prove Mridul is a maintainer
    * Review/sign the lifter agreement
  * The way we think this works:
    - We have a release on the conda-forge channel as well as PyPI - different income for the two
      * Depends on how tidelift's clients use these
  * Dan and/or Mridul will sign the agreement


## Discussion

- [ ] Social media
    * NetworkX twitter
    * blog.scientific-python.org

TODO: Fix Grey/Green checkmark problem on GH!
