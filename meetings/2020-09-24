# NetworkX Developer Discussions: Â September 24th, 2020

In attendance: Jarrod, Dan, Mridul, Ross, Stefan

## Topics

- Welcome and news 

  * Potential sprint: [Scipy Japan](https://www.scipyjapan.scipy.org/sprints) Nov. 1st-2nd

## Follow up from last week

- NXEP 2 (add slicing to \*View containers)
  * Summary of last meeting's discussion added to the `Discussion` section of NXEP2 in https://github.com/networkx/networkx/pull/4218
  * https://github.com/python/peps/blob/master/pep-0637.txt

- EM: more code to look at? https://github.com/ericmjl/protein-interaction-network/blob/master/proteingraph/conversion.py
  * Added in PR https://github.com/networkx/networkx/pull/4217
  * See http://xarray.pydata.org/en/stable/generated/xarray.Dataset.from_dict.html#xarray.Dataset.from_dict 
   
- pagerank is a good example of some code in NetworkX that could benefit from thinking about how to allow algorithms to work directly with a sparse array data structure instead of the dict-of-dict sparse structure.  https://github.com/networkx/networkx/issues/4207 SciPy sparse matrices as a backend?

  * One approach: a sparse adjacency matrix as an attribute of a Graph (maybe a FrozenGraph?). Then `pagerank` will use the sparse matrix form for computation if it is up-to-date (keep track of with flags?)
  * Another idea: `pagerank` operates based on the type of the input, e.g.
    ```python
    def pagerank(input_obj):
        if isinstance(input_obj, scipy.sparse.csr_matrix):
            # Use pagerank_scipy
        if isinstance(input_obj, numpy.ndarray):
            # Use pagerank_numpy
        if isinstance(input_obj, nx.Graph):
            try: 
            # Convert to scipy.sparse and use pagerank_scipy
            # as this is still faster than the Python 
            # implementation
            except ImportError:
                # pure python pagerank()
    ```
  * https://pypi.org/project/perfplot/0.2.1/

## Discussion

 - Scipy Japan sprint - need more info

 - Tidelift/NumFocus: where does NetworkX stand?
   * Investigate fiscal sponsorship & necessary actions on NX's part


Previous topics
===============

  - def _dijkstra_multisource()   
      Q: How much is combining all versions of dijkstra into one routine slowing it down? (I feel like the contributor march to remove repeated code has not paid attention to performance.)
      (multisource/source, pred, paths, weight function vs dict-lookup, weight None-> no edge, )
  - unweighted shortest_path might have similar issue, but I think it doesn't have as many options. 
  - pagerank, pagerank_numpy and pagerank_scipy don't talk about which to use much. Can we rename to prioritize the scipy version? Is there a faster method than power iteration in python to get the "largest" eigenvector?
  - cluster.py was written long ago and speed compares poorly with graphtool (global clustering is called transitivity in NX) probably because no one has looked at this in a while.
  - dag.py has some code that is really inefficient.
  - Find loops that use G.edges(n). That idiom could be replaced with a single call returning an Edgeview with lookup -- or use G.adj. Sometimes this idiom is used to avoid handling of edge keys in MultiGraph with code that also works for Graph. There should be a better way.
  - sparsifiers, planarity and simple_paths might be worth looking at for loop speed-ups.
  - k-core (core.py) shows as slow in graphtool comparison. Probably worth looking at.
  - similarity code is pretty new and lots of for loops. Probably worth looking at.
