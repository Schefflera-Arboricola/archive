# NetworkX Developer Discussions: February 21st 2023

Previous meeting notes available [here](https://github.com/networkx/archive/tree/main/meetings). Please feel free to add topics for discussion and news items below.

**In attendance:** Paula, Sultan, Dan, Mridul, Ross, Erik

## Welcome and news

* New meeting time: Tuesdays, 9:30 - 10:30AM PST
* [Notes from roadmap review](https://github.com/networkx/archive/blob/main/meetings/2023-01-24_roadmap_discussion.md)  We still need to update the roadmap in the docs.

## Important dates/deadlines

* Outreachy term ends March 3
* SciPy conference tutorial proposals due: ~~Feb. 22nd~~ March 1
* GSOC ??  (viz?  graphBLAS backend?) - Need projects for the "mentored projects" page
  - GSoC Deadline: 2/7
    - Apply under numfocus umbrella
    - Two pings about it on NetworkX discuss list
* NetworkX 3.1: Set for March 31. Our goal is to release a last version with Python 3.8 support.
    * Update the 3.1 release date on documentation and github pages.

## Follow-up from last week

* Feedback on the NumFOCUS lawyers' response to the memgraph folks?
  * Response on steering council mailing list was positive. Give the green light?
  * TBD
    
* Latest plausible updates?
    * TIL bounce rate - homepage 77% people leave after looking at the homepage.
      - Let's see what happens after a networkx.org homepage redesign. Could be an indication that users don't know where to click?
    * Plausible enabled for documentation too, but only devdocs
      - Homepage, gallery, tutorial are three most visited pages (in that order)

* Pdf doc building
  - [name=rossbar]: review PR
  - Still haven't done this!
  
## Topics

* Contributor-to-maintainer pathway
  - How to better onboard folks
  - Related: review the "core developer" list

* Python 3.9 will become the minimum version in April:
  - New features in 3.9 to be aware of:
    * `graphlib.topological_sort`
    * Dict merge and update features
    
* Milestone updates for future releases:
  - 3.1: March 31st
  - 3.2: August 31st - give a couple months to prepare for Python 3.12
  
* Reviews marked `close ?`


## Long-term tracking items

- Stop building/shipping pdf version of documentation?
  * This is being considered by both scipy and numpy and seems to have garnered mostly positive feedback
    - related scipy issue: https://github.com/scipy/scipy/issues/15635
  * revisit after 2.8 release -- We'll keep it for v3.0 and then look at removing it after that.
  * Keep up-to-date with feedback from other projects that are considering this

- Adopt `pyproject.toml`?
  * [This article was a nice overview](https://snarky.ca/what-the-heck-is-pyproject-toml/)
  * Since NX doesn't have build deps, there's no strong motivation to do so other than "other projects are doing it"
  * Potential "benefit" - store metadata/configs for additional tooling (e.g. type checkers, linters) in one place. [PEP 621](https://peps.python.org/pep-0621/) 
  * Jarrod reports that there may be many changes to the systems in the lead up to Python 3.12. So maybe we should delay consideration of changing to this until then. If we do adopt pyproject.toml, we may want to autogenerate it from the requirements file. For example, see what we did in scikit-image:
https://github.com/scikit-image/scikit-image/blob/main/tools/generate_pyproject.toml.py

- helpful to have a place for best-practices like nbunch, view vs dict, subgraph vs subgraph.copy()
  * nx-guides would be a good place for this!

- Keyword-only and maybe position-only input. Candidate subpackage to start changing code to keyword-only is the nx_pylab. (see [SLEP009](https://scikit-learn-enhancement-proposals.readthedocs.io/en/latest/slep009/proposal.html) for how sklearn did this)

- We should try to automate the release process as much as possible so that we could remove a human from the release process. conda-forge has a very automated release system. Would a SPEC covering automated releases be reasonable?
    - Not clear what the advanatges of automating the release process would be. The process is [documented](https://github.com/networkx/networkx/blob/main/doc/developer/release.rst) What would make this better?
    - Why would automating things further not cause problems?

- Review public interface: For v4.0 we should be looking at the import structure?  Some subpackages are not imported to the main namespace. We have decided that based on history of how they were first committed. Is there a good way to decide which should require an extra referal: `network.community.modularity` instead of `networkx.modularity`?
  - First decision: what do we *want* the interface to be?
  - Module/pkg `__dir__` provides a nice way to modify discoverability of modules/packages **without** breaking existing code
  - NX-guide idea: model/visualize the package as a DAG (thanks Matt!)

- keywords arrows, arrowstyle, connectionstyle. Can we improve this interface? [#5694](https://github.com/networkx/networkx/pull/5694) and a link to the [current interface](https://github.com/networkx/networkx/blob/2c904d18dc79df3acd64495ef64c6ff4674992a0/networkx/drawing/nx_pylab.py#L537)
    - Now raise UserWarnings when users request features that are not available for the underlying edge-viz object (e.g. LineCollection)
    - Is there a better, more wholistic solution?
    - Need to indicate:
      o FancyArrowPatch or LineCollection
      o The arrowstyle (head or not or both, etc)
      o The connectionstyle (arc bendable etc)
    - Maybe changing the name of `arrows` to `fancyedges` would help
    - New logic could be:  If non-default value for either arrowstyle or connectionstyle then switch to FancyArrowPatch.
    - milestone this for v3.0

- Property-based testing
  * Check out `hypothesis` for setting up property-based testing
  * Developing good property-based tests:
    - Reference "naive" (but correct) implementation
    - Generate random graphs, evaluate them for the property you want
    - Pump these through the naive implementation and collect interesting cases for test suite

- Temporal networks: how to think about these
  * seems to be a lot of interest from different communities, but no standard approach yet...
  * Having a use-case to drive the design of a data structure would be good
  
- nx-guides
  * We need a contributor guide :book: [name=Mridul]
  * Dependency management for tutorials - how to strike a balance between tools people use and maintainability

- New contributors
  * So many good students/contributions - how do we keep the ball rolling (even if we can only accept 1 or a subset of them for this round)
    - Add something to contributor guide about where to look for good issues (e.g. add missing docstring examples)
    - Link to [first issue tag](https://github.com/networkx/networkx/labels/Good%20First%20Issue) on github?
    
- Revisiting our pytest `slow` mark:
  * The `slow` tests are run w/ each push/PR in the coverage job; however, it's not necessarily true that the slow tests improve coverage!
  * Could save a lot of CI time by having a separate category (e.g. `pytest.mark.comprehensive`?) that is for tests that are slow but *don't* affect coverage. These could be run less frequently (scheduled job?) and potentially save several minutes for each push
    - General consensus: seems like a good idea
    - ~~(Jarrod) maybe worth waiting until after the code removal sprint?~~
      - deprecated code removed

- Other CI-saving ideas
    - All tests should depend on the lint action, so all the other tests fail fast.

## Discussion

- [ ] Social media
    * NetworkX twitter
    * blog.scientific-python.org